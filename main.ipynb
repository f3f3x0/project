{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EMNIST dataset\n",
    "\n",
    "train_data = torchvision.datasets.EMNIST(\n",
    "    root='.data',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False,\n",
    "    split='letters'\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.EMNIST(\n",
    "    root='.data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False,\n",
    "    split='letters'     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label: u\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157,\n",
       "         0.0157, 0.0353, 0.1255, 0.1255, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392, 0.4431,\n",
       "         0.4980, 0.5490, 0.7961, 0.7961, 0.3059, 0.0275, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0078, 0.0353, 0.1255, 0.2000, 0.5020, 0.9529,\n",
       "         0.9804, 0.9804, 0.9961, 0.9961, 0.7882, 0.1255, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0157,\n",
       "         0.0157, 0.0157, 0.0863, 0.3216, 0.5451, 0.8000, 0.8706, 0.9608, 0.9804,\n",
       "         0.9647, 0.9373, 0.9922, 1.0000, 0.8510, 0.1451, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0157, 0.0353, 0.1255, 0.1529, 0.3216, 0.4902,\n",
       "         0.4980, 0.4980, 0.6784, 0.9098, 0.9804, 0.9922, 0.9922, 0.9569, 0.5529,\n",
       "         0.4549, 0.4471, 0.9176, 0.9961, 0.8000, 0.1255, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0078, 0.2980, 0.7882, 0.8706, 0.9608, 0.9804, 0.9882, 0.9961,\n",
       "         0.9961, 0.9922, 0.9804, 0.9608, 0.8157, 0.5490, 0.4471, 0.1804, 0.0039,\n",
       "         0.0078, 0.3216, 0.9137, 0.9922, 0.4510, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0118, 0.4353, 0.9412, 0.9804, 0.9804, 0.9137, 0.8510, 0.8510,\n",
       "         0.8510, 0.8000, 0.5059, 0.4471, 0.1804, 0.0353, 0.0157, 0.0000, 0.0000,\n",
       "         0.0353, 0.5451, 0.9804, 0.9647, 0.1804, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.1255, 0.4431, 0.4980, 0.4980, 0.3216, 0.1529, 0.1451,\n",
       "         0.1451, 0.1255, 0.0196, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1804, 0.8157, 0.9922, 0.8627, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0157, 0.0157, 0.0157, 0.0078, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314,\n",
       "         0.4980, 0.9647, 0.9843, 0.6667, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804,\n",
       "         0.8157, 0.9922, 0.8627, 0.3098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.5020,\n",
       "         0.9608, 0.9569, 0.4980, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.8667,\n",
       "         0.9843, 0.6863, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0078, 0.0196, 0.0863, 0.3294, 0.7333, 0.9961,\n",
       "         0.9451, 0.6235, 0.5020, 0.4471, 0.1490, 0.0784, 0.0039, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0784, 0.1451,\n",
       "         0.1451, 0.1451, 0.1529, 0.3216, 0.4980, 0.6784, 0.9098, 0.9882, 0.9961,\n",
       "         0.9961, 0.9843, 0.9804, 0.9608, 0.8471, 0.6235, 0.1843, 0.0196, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.6196, 0.8431,\n",
       "         0.8510, 0.8510, 0.8510, 0.9137, 0.9765, 0.9882, 0.9961, 0.9961, 0.9804,\n",
       "         0.9804, 0.9804, 0.9804, 0.9804, 0.9922, 0.9686, 0.7451, 0.1294, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4431, 0.9529, 0.9961,\n",
       "         0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9882, 0.9765, 0.9098, 0.5490,\n",
       "         0.4980, 0.4980, 0.4980, 0.5059, 0.9176, 0.9961, 0.9137, 0.3216, 0.0078,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4235, 0.8353, 0.8510,\n",
       "         0.8510, 0.8510, 0.8510, 0.8510, 0.8431, 0.6745, 0.4980, 0.3216, 0.0353,\n",
       "         0.0157, 0.0157, 0.0157, 0.0275, 0.6784, 0.9882, 0.9765, 0.4902, 0.0157,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1451, 0.1451,\n",
       "         0.1451, 0.1451, 0.1451, 0.1451, 0.1451, 0.0824, 0.0196, 0.0078, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.5098, 0.9804, 0.9804, 0.4980, 0.0157,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0078, 0.6745, 0.9882, 0.9804, 0.4980, 0.0157,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0039, 0.1412, 0.9176, 0.9961, 0.9098, 0.3216, 0.0078,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0784, 0.6196, 0.9922, 0.9843, 0.6706, 0.0863, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.1255, 0.7843, 0.9922, 0.9020, 0.3255, 0.0118, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0275, 0.3529, 0.7922, 0.4784, 0.0784, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0275, 0.1255, 0.0314, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = train_data.data[:20] / 255\n",
    "y_train = train_data.targets[:20]\n",
    "\n",
    "# Show some random image of a character and its label\n",
    "\n",
    "img_index = 16\n",
    "img = x_train[img_index]\n",
    "print(\"Image Label: \" + str(chr(y_train[img_index]+96)))\n",
    "plt.imshow(img.reshape((28,28)))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1,   2,   3,   4,  29,  30,  31,  32,  57,  58,  59,  60,  85,  86,\n",
       "           87,  88],\n",
       "         [  5,   6,   7,   8,  33,  34,  35,  36,  61,  62,  63,  64,  89,  90,\n",
       "           91,  92],\n",
       "         [  9,  10,  11,  12,  37,  38,  39,  40,  65,  66,  67,  68,  93,  94,\n",
       "           95,  96],\n",
       "         [ 13,  14,  15,  16,  41,  42,  43,  44,  69,  70,  71,  72,  97,  98,\n",
       "           99, 100],\n",
       "         [ 17,  18,  19,  20,  45,  46,  47,  48,  73,  74,  75,  76, 101, 102,\n",
       "          103, 104],\n",
       "         [ 21,  22,  23,  24,  49,  50,  51,  52,  77,  78,  79,  80, 105, 106,\n",
       "          107, 108],\n",
       "         [ 25,  26,  27,  28,  53,  54,  55,  56,  81,  82,  83,  84, 109, 110,\n",
       "          111, 112]],\n",
       "\n",
       "        [[113, 114, 115, 116, 141, 142, 143, 144, 169, 170, 171, 172, 197, 198,\n",
       "          199, 200],\n",
       "         [117, 118, 119, 120, 145, 146, 147, 148, 173, 174, 175, 176, 201, 202,\n",
       "          203, 204],\n",
       "         [121, 122, 123, 124, 149, 150, 151, 152, 177, 178, 179, 180, 205, 206,\n",
       "          207, 208],\n",
       "         [125, 126, 127, 128, 153, 154, 155, 156, 181, 182, 183, 184, 209, 210,\n",
       "          211, 212],\n",
       "         [129, 130, 131, 132, 157, 158, 159, 160, 185, 186, 187, 188, 213, 214,\n",
       "          215, 216],\n",
       "         [133, 134, 135, 136, 161, 162, 163, 164, 189, 190, 191, 192, 217, 218,\n",
       "          219, 220],\n",
       "         [137, 138, 139, 140, 165, 166, 167, 168, 193, 194, 195, 196, 221, 222,\n",
       "          223, 224]],\n",
       "\n",
       "        [[225, 226, 227, 228, 253, 254, 255, 256, 281, 282, 283, 284, 309, 310,\n",
       "          311, 312],\n",
       "         [229, 230, 231, 232, 257, 258, 259, 260, 285, 286, 287, 288, 313, 314,\n",
       "          315, 316],\n",
       "         [233, 234, 235, 236, 261, 262, 263, 264, 289, 290, 291, 292, 317, 318,\n",
       "          319, 320],\n",
       "         [237, 238, 239, 240, 265, 266, 267, 268, 293, 294, 295, 296, 321, 322,\n",
       "          323, 324],\n",
       "         [241, 242, 243, 244, 269, 270, 271, 272, 297, 298, 299, 300, 325, 326,\n",
       "          327, 328],\n",
       "         [245, 246, 247, 248, 273, 274, 275, 276, 301, 302, 303, 304, 329, 330,\n",
       "          331, 332],\n",
       "         [249, 250, 251, 252, 277, 278, 279, 280, 305, 306, 307, 308, 333, 334,\n",
       "          335, 336]],\n",
       "\n",
       "        [[337, 338, 339, 340, 365, 366, 367, 368, 393, 394, 395, 396, 421, 422,\n",
       "          423, 424],\n",
       "         [341, 342, 343, 344, 369, 370, 371, 372, 397, 398, 399, 400, 425, 426,\n",
       "          427, 428],\n",
       "         [345, 346, 347, 348, 373, 374, 375, 376, 401, 402, 403, 404, 429, 430,\n",
       "          431, 432],\n",
       "         [349, 350, 351, 352, 377, 378, 379, 380, 405, 406, 407, 408, 433, 434,\n",
       "          435, 436],\n",
       "         [353, 354, 355, 356, 381, 382, 383, 384, 409, 410, 411, 412, 437, 438,\n",
       "          439, 440],\n",
       "         [357, 358, 359, 360, 385, 386, 387, 388, 413, 414, 415, 416, 441, 442,\n",
       "          443, 444],\n",
       "         [361, 362, 363, 364, 389, 390, 391, 392, 417, 418, 419, 420, 445, 446,\n",
       "          447, 448]],\n",
       "\n",
       "        [[449, 450, 451, 452, 477, 478, 479, 480, 505, 506, 507, 508, 533, 534,\n",
       "          535, 536],\n",
       "         [453, 454, 455, 456, 481, 482, 483, 484, 509, 510, 511, 512, 537, 538,\n",
       "          539, 540],\n",
       "         [457, 458, 459, 460, 485, 486, 487, 488, 513, 514, 515, 516, 541, 542,\n",
       "          543, 544],\n",
       "         [461, 462, 463, 464, 489, 490, 491, 492, 517, 518, 519, 520, 545, 546,\n",
       "          547, 548],\n",
       "         [465, 466, 467, 468, 493, 494, 495, 496, 521, 522, 523, 524, 549, 550,\n",
       "          551, 552],\n",
       "         [469, 470, 471, 472, 497, 498, 499, 500, 525, 526, 527, 528, 553, 554,\n",
       "          555, 556],\n",
       "         [473, 474, 475, 476, 501, 502, 503, 504, 529, 530, 531, 532, 557, 558,\n",
       "          559, 560]],\n",
       "\n",
       "        [[561, 562, 563, 564, 589, 590, 591, 592, 617, 618, 619, 620, 645, 646,\n",
       "          647, 648],\n",
       "         [565, 566, 567, 568, 593, 594, 595, 596, 621, 622, 623, 624, 649, 650,\n",
       "          651, 652],\n",
       "         [569, 570, 571, 572, 597, 598, 599, 600, 625, 626, 627, 628, 653, 654,\n",
       "          655, 656],\n",
       "         [573, 574, 575, 576, 601, 602, 603, 604, 629, 630, 631, 632, 657, 658,\n",
       "          659, 660],\n",
       "         [577, 578, 579, 580, 605, 606, 607, 608, 633, 634, 635, 636, 661, 662,\n",
       "          663, 664],\n",
       "         [581, 582, 583, 584, 609, 610, 611, 612, 637, 638, 639, 640, 665, 666,\n",
       "          667, 668],\n",
       "         [585, 586, 587, 588, 613, 614, 615, 616, 641, 642, 643, 644, 669, 670,\n",
       "          671, 672]],\n",
       "\n",
       "        [[673, 674, 675, 676, 701, 702, 703, 704, 729, 730, 731, 732, 757, 758,\n",
       "          759, 760],\n",
       "         [677, 678, 679, 680, 705, 706, 707, 708, 733, 734, 735, 736, 761, 762,\n",
       "          763, 764],\n",
       "         [681, 682, 683, 684, 709, 710, 711, 712, 737, 738, 739, 740, 765, 766,\n",
       "          767, 768],\n",
       "         [685, 686, 687, 688, 713, 714, 715, 716, 741, 742, 743, 744, 769, 770,\n",
       "          771, 772],\n",
       "         [689, 690, 691, 692, 717, 718, 719, 720, 745, 746, 747, 748, 773, 774,\n",
       "          775, 776],\n",
       "         [693, 694, 695, 696, 721, 722, 723, 724, 749, 750, 751, 752, 777, 778,\n",
       "          779, 780],\n",
       "         [697, 698, 699, 700, 725, 726, 727, 728, 753, 754, 755, 756, 781, 782,\n",
       "          783, 784]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[x + 1 for x in range(28 * y, 28 * (y + 1))] for y in range(28)])\n",
    "c = a.split(4, dim=0)\n",
    "torch.stack([torch.stack(d.split(4, dim=1)).view(7, 16) for d in c])\n",
    "# c.split(4, dim=2)\n",
    "# d = c[0]\n",
    "# d = d.split(4, dim=1)\n",
    "# d = torch.stack(d)\n",
    "# d.view(7, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a particular image and convert to the right type\n",
    "temp_image = torch.stack([torch.stack(d.split(4, dim=1)).view(7, 16) for d in img.split(4, dim=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the first layer, scanning from four directions\n",
    "\n",
    "hidden_units1 = 2\n",
    "input_feature1 = 16\n",
    "\n",
    "# Input gate\n",
    "weight_input_gate1_tl = torch.randn((input_feature1, hidden_units1), requires_grad=True)\n",
    "weight_input_state1_tl = torch.randn((hidden_units1, hidden_units1), requires_grad=True)\n",
    "weight_input_cellout1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "bias_input_gate1_tl = torch.randn(hidden_units1, requires_grad=True)\n",
    "\n",
    "# Forget gate\n",
    "weight_forget_gate1_tl = torch.randn((2, input_feature1, hidden_units1), requires_grad=True)\n",
    "weight_forget_cellout1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "weight_forget_state1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "bias_forget_gate1_tl = torch.randn(hidden_units1, requires_grad=True)\n",
    "\n",
    "# Cell\n",
    "weight_cell1_tl = torch.randn((input_feature1, hidden_units1), requires_grad=True)\n",
    "weight_cell_cellout1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "bias_cell1_tl = torch.randn(hidden_units1, requires_grad=True)\n",
    "\n",
    "# Output gate\n",
    "weight_output_gate1_tl = torch.randn((input_feature1, hidden_units1), requires_grad=True)\n",
    "weight_output_cellout1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "weight_output_state1_tl = torch.randn((hidden_units1, hidden_units1), requires_grad=True)\n",
    "bias_output_gate1_tl = torch.randn(hidden_units1, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network of the first layer, containing four directions\n",
    "\n",
    "# Starting from top left\n",
    "\n",
    "def forward1_tl(image):\n",
    "    # Suppose image is a tensor of 7*7*16, all 49 blocks\n",
    "    states = np.zeros((7, 7)).tolist()\n",
    "    cell_outputs = np.zeros((7, 7)).tolist()\n",
    "\n",
    "    # Top left\n",
    "    for row in range(7):\n",
    "        for col in range(7):\n",
    "            _input = image[row][col]\n",
    "            # Deal with input gate\n",
    "            input_gate = _input @ weight_input_gate1_tl + bias_input_gate1_tl\n",
    "            if row > 0:\n",
    "                temp1 = states[row - 1][col] @ weight_input_state1_tl\n",
    "                temp2 = cell_outputs[row - 1][col] @ weight_input_cellout1_tl[0]\n",
    "                input_gate += temp1 + temp2\n",
    "            if col > 0:\n",
    "                temp1 = states[row][col - 1] @ weight_input_state1_tl\n",
    "                temp2 = cell_outputs[row][col - 1] @ weight_input_cellout1_tl[0]\n",
    "                input_gate += temp1 + temp2\n",
    "            input_gate = input_gate.sigmoid()\n",
    "\n",
    "            # Deal with forget gate\n",
    "            forget_gates = []\n",
    "            for d in range(2):\n",
    "                forget_gate = _input @ weight_forget_gate1_tl[d] + bias_forget_gate1_tl\n",
    "                if row > 0:\n",
    "                    forget_gate += cell_outputs[row - 1][col] @ weight_forget_cellout1_tl[0]\n",
    "                if col > 0:\n",
    "                    forget_gate += cell_outputs[row][col - 1] @ weight_forget_cellout1_tl[1]\n",
    "                if d == 0 and row > 0:\n",
    "                    forget_gate += states[row - 1][col] @ weight_forget_state1_tl[0]\n",
    "                if d == 1 and col > 0:\n",
    "                    forget_gate += states[row][col - 1] @ weight_forget_state1_tl[1]\n",
    "                forget_gates.append(forget_gate.sigmoid())\n",
    "            \n",
    "            # Deal with cell\n",
    "            cell = _input @ weight_cell1_tl + bias_cell1_tl\n",
    "            if row > 0:\n",
    "                cell += cell_outputs[row - 1][col] @ weight_cell_cellout1_tl[0]\n",
    "            if col > 0:\n",
    "                cell += cell_outputs[row][col - 1] @ weight_cell_cellout1_tl[1]\n",
    "            \n",
    "            # Deal with state\n",
    "            state = input_gate * cell.tanh()\n",
    "            if row > 0:\n",
    "                state += states[row - 1][col] * forget_gates[0]\n",
    "            if col > 0:\n",
    "                state += states[row][col - 1] * forget_gates[1]\n",
    "            states[row][col] = state\n",
    "\n",
    "            # Deal with output gate\n",
    "            output = _input @ weight_output_gate1_tl + bias_output_gate1_tl + state @ weight_output_state1_tl\n",
    "            if row > 0:\n",
    "                output += cell_outputs[row - 1][col] @ weight_output_cellout1_tl[0]\n",
    "            if col > 0:\n",
    "                output += cell_outputs[row][col - 1] @ weight_output_cellout1_tl[1]\n",
    "            output = output.sigmoid()\n",
    "\n",
    "            # Deal with cell output\n",
    "            cell_output = output * state.tanh()\n",
    "            cell_outputs[row][col] = cell_output\n",
    "    \n",
    "    return cell_outputs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([ 0.0351, -0.1234], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0257, -0.1725], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0104, -0.1715], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0033, -0.1485], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0104, -0.0592], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0459, -0.2389], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0081, -0.1095], grad_fn=<MulBackward0>)],\n",
       " [tensor([0.0298, 0.0128], grad_fn=<MulBackward0>),\n",
       "  tensor([0.0778, 0.2276], grad_fn=<MulBackward0>),\n",
       "  tensor([0.1352, 0.6430], grad_fn=<MulBackward0>),\n",
       "  tensor([0.4754, 0.6785], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.9181, -0.1515], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.9972, -0.3258], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.9927, -0.3289], grad_fn=<MulBackward0>)],\n",
       " [tensor([ 0.3899, -0.0749], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.7000, -0.5099], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.6728, -0.5000], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.4878, -0.5664], grad_fn=<MulBackward0>),\n",
       "  tensor([0.5257, 0.0881], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.8824, -0.4540], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.8516, -0.2770], grad_fn=<MulBackward0>)],\n",
       " [tensor([ 0.3433, -0.1411], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.3596, -0.0875], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.1884, -0.0597], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0255, -0.0237], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.5616, -0.1912], grad_fn=<MulBackward0>),\n",
       "  tensor([0.6103, 0.0606], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.8636, -0.2713], grad_fn=<MulBackward0>)],\n",
       " [tensor([ 0.2173, -0.1307], grad_fn=<MulBackward0>),\n",
       "  tensor([0.2630, 0.0266], grad_fn=<MulBackward0>),\n",
       "  tensor([0.3122, 0.5947], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.4784, -0.2230], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.6527, -0.6145], grad_fn=<MulBackward0>),\n",
       "  tensor([0.7981, 0.2053], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.7173, -0.6501], grad_fn=<MulBackward0>)],\n",
       " [tensor([ 0.1071, -0.1307], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.1991, -0.1807], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.2108, -0.4167], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.1914, -0.1310], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.1390, -0.0309], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.1759, -0.6202], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0673, -0.1357], grad_fn=<MulBackward0>)],\n",
       " [tensor([ 0.0566, -0.1306], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0699, -0.1020], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0730, -0.0389], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0431, -0.0358], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0220, -0.0239], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0465, -0.0079], grad_fn=<MulBackward0>),\n",
       "  tensor([ 0.0156, -0.0071], grad_fn=<MulBackward0>)]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward1_tl(temp_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
