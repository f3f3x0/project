{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EMNIST dataset\n",
    "\n",
    "train_data = torchvision.datasets.EMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True,\n",
    "    split='letters'\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.EMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False,\n",
    "    split='letters'     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.data / 255\n",
    "y_train = train_data.targets - 1\n",
    "\n",
    "# Show some random image of a character and its label\n",
    "\n",
    "img_index = 16\n",
    "img = x_train[img_index]\n",
    "print(\"Image Label: \" + str(chr(y_train[img_index]+96)))\n",
    "plt.imshow(img.reshape((28,28)))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[x + 1 for x in range(28 * y, 28 * (y + 1))] for y in range(28)]).view(1, 1, 28, 28).float()\n",
    "c = F.unfold(a, kernel_size=(4, 4), stride=4).transpose(1, 2).view(1, 7, 7, 16)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a particular image and convert to the right type\n",
    "temp_image = F.unfold(img.view(1, 1, 28, 28), kernel_size=(4, 4), stride=4).transpose(1, 2).view(7, 7, 16)\n",
    "temp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoDimensionalLSTM_fixed_direction:\n",
    "    \"\"\"A 2-D LSTM scanning in the given direction.\n",
    "       The input should be a 3-D tensor of shape row*col*input_feature.\n",
    "       The output should be a 2-D tensor of shape row*(col*hidden_units).\n",
    "       \"\"\"\n",
    "    def __init__(self, input_features, hidden_units, rows, cols, row_decre, col_decre):\n",
    "        self.input_features = input_features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.rows, self.cols = rows, cols\n",
    "        self.row_decre = row_decre\n",
    "        self.col_decre = col_decre\n",
    "        self.row_init, self.col_init = rows[0], cols[0]\n",
    "\n",
    "        # To avoid scattering of tanh(), initialization issue needs to be solved!!!\n",
    "\n",
    "        # Input gate\n",
    "        self.weight_input_gate = torch.randn((input_features, hidden_units), requires_grad=True) * 0.01\n",
    "        self.weight_input_state = torch.randn((hidden_units, hidden_units), requires_grad=True) * 0.01\n",
    "        self.weight_input_cellout = torch.randn((2, hidden_units, hidden_units), requires_grad=True) * 0.01\n",
    "        self.bias_input_gate = torch.randn(hidden_units, requires_grad=True) * 0.01\n",
    "\n",
    "        # Forget gate\n",
    "        self.weight_forget_gate = torch.randn((2, input_features, hidden_units), requires_grad=True) * 0.01\n",
    "        self.weight_forget_cellout = torch.randn((2, 2, hidden_units, hidden_units), requires_grad=True) * 0.01\n",
    "        self.weight_forget_state = torch.randn((2, hidden_units, hidden_units), requires_grad=True) * 0.01\n",
    "        self.bias_forget_gate = torch.randn((2, hidden_units), requires_grad=True) * 0.01\n",
    "\n",
    "        # Cell\n",
    "        self.weight_cell = torch.randn((input_features, hidden_units), requires_grad=True) * 0.01\n",
    "        self.weight_cell_cellout = torch.randn((2, hidden_units, hidden_units), requires_grad=True) * 0.01\n",
    "        self.bias_cell = torch.randn(hidden_units, requires_grad=True) * 0.01\n",
    "\n",
    "        # Output gate\n",
    "        self.weight_output_gate = torch.randn((input_features, hidden_units), requires_grad=True) * 0.01\n",
    "        self.weight_output_cellout = torch.randn((2, hidden_units, hidden_units), requires_grad=True) * 0.01\n",
    "        self.weight_output_state = torch.randn((hidden_units, hidden_units), requires_grad=True) * 0.01\n",
    "        self.bias_output_gate = torch.randn(hidden_units, requires_grad=True) * 0.01\n",
    "\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight_input_gate, \n",
    "                self.weight_input_state, \n",
    "                self.weight_input_cellout,\n",
    "                self.bias_input_gate,  # Input gate\n",
    "                self.weight_forget_gate, \n",
    "                self.weight_forget_cellout,\n",
    "                self.weight_forget_state, \n",
    "                self.bias_forget_gate,  # Forget gate\n",
    "                self.weight_cell, \n",
    "                self.weight_cell_cellout,\n",
    "                self.bias_cell,  # Cell\n",
    "                self.weight_output_gate, \n",
    "                self.weight_output_cellout, \n",
    "                self.weight_output_state, \n",
    "                self.bias_output_gate] # Output gate\n",
    "    \n",
    "    def __call__(self, input_image):\n",
    "        states = np.zeros((len(self.rows), len(self.cols))).tolist()\n",
    "        cell_outputs = np.zeros((len(self.rows), len(self.cols))).tolist()\n",
    "\n",
    "        for row in self.rows:\n",
    "            for col in self.cols:\n",
    "                _input = input_image[row][col]\n",
    "                row_m = row + self.row_decre\n",
    "                col_m = col + self.col_decre\n",
    "                \n",
    "                # Deal with input gate\n",
    "                input_gate = _input @ self.weight_input_gate + self.bias_input_gate\n",
    "                if row != self.row_init:\n",
    "                    input_gate += states[row_m][col] @ self.weight_input_state \\\n",
    "                                + cell_outputs[row_m][col] @ self.weight_input_cellout[0]\n",
    "                if col != self.col_init:\n",
    "                    input_gate += states[row][col_m] @ self.weight_input_state \\\n",
    "                                + cell_outputs[row][col_m] @ self.weight_input_cellout[1]\n",
    "                input_gate = input_gate.sigmoid()\n",
    "\n",
    "                # Deal with forget gate\n",
    "                forget_gates = []\n",
    "                for dim in range(2):\n",
    "                    forget_gate = _input @ self.weight_forget_gate[dim] + self.bias_forget_gate[dim]\n",
    "                    if row != self.row_init:\n",
    "                        forget_gate += cell_outputs[row_m][col] @ self.weight_forget_cellout[0][dim]\n",
    "                    if col != self.col_init:\n",
    "                        forget_gate += cell_outputs[row][col_m] @ self.weight_forget_cellout[1][dim]\n",
    "                    if dim == 0 and row != self.row_init:\n",
    "                        forget_gate += states[row_m][col] @ self.weight_forget_state[dim]\n",
    "                    if dim == 1 and col != self.col_init:\n",
    "                        forget_gate += states[row][col_m] @ self.weight_forget_state[dim]\n",
    "                    forget_gates.append(forget_gate.sigmoid())\n",
    "\n",
    "                # Deal with cell\n",
    "                cell = _input @ self.weight_cell + self.bias_cell\n",
    "                if row != self.row_init:\n",
    "                    cell += cell_outputs[row_m][col] @ self.weight_cell_cellout[0]\n",
    "                if col != self.col_init:\n",
    "                    cell += cell_outputs[row][col_m] @ self.weight_cell_cellout[1]\n",
    "\n",
    "                # Deal with state\n",
    "                state = input_gate * cell.tanh()\n",
    "                if row != self.row_init:\n",
    "                    state += states[row_m][col] @ forget_gates[0]\n",
    "                if col != self.col_init:\n",
    "                    state += states[row][col_m] @ forget_gates[1]\n",
    "                states[row][col] = state\n",
    "\n",
    "                # Deal with output gate\n",
    "                output_gate = _input @ self.weight_output_gate + self.bias_output_gate + state @ self.weight_output_state\n",
    "                if row != self.row_init:\n",
    "                    output_gate += cell_outputs[row_m][col] @ self.weight_cell_cellout[0]\n",
    "                if col != self.col_init:\n",
    "                    output_gate += cell_outputs[row][col_m] @ self.weight_cell_cellout[1]\n",
    "                output_gate = output_gate.sigmoid()\n",
    "\n",
    "                # Deal with cell output\n",
    "                cell_outputs[row][col] = output_gate * state.tanh()\n",
    "\n",
    "        return torch.stack([torch.stack(row_cell_outputs) for row_cell_outputs in cell_outputs]).view(49, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoDimensionalLSTM:\n",
    "    def __init__(self, input_features, hidden_units, row_size, col_size):\n",
    "        self.hidden_units = hidden_units\n",
    "        self.row_size, self.col_size = row_size, col_size\n",
    "        self.top_left = TwoDimensionalLSTM_fixed_direction(input_features,\n",
    "                                                           hidden_units,\n",
    "                                                           np.arange(row_size),\n",
    "                                                           np.arange(col_size),\n",
    "                                                           -1, -1)\n",
    "        self.top_right = TwoDimensionalLSTM_fixed_direction(input_features,\n",
    "                                                            hidden_units,\n",
    "                                                            np.arange(row_size),\n",
    "                                                            np.arange(col_size - 1, -1, -1),\n",
    "                                                            -1, 1)\n",
    "        self.down_left = TwoDimensionalLSTM_fixed_direction(input_features,\n",
    "                                                            hidden_units,\n",
    "                                                            np.arange(row_size - 1, -1, -1),\n",
    "                                                            np.arange(col_size),\n",
    "                                                            1, -1)\n",
    "        self.down_right = TwoDimensionalLSTM_fixed_direction(input_features,\n",
    "                                                             hidden_units,\n",
    "                                                             np.arange(row_size - 1, -1, -1),\n",
    "                                                             np.arange(col_size - 1, -1, -1),\n",
    "                                                             1, 1)\n",
    "        self.weight = torch.randn((4 * hidden_units, hidden_units), requires_grad=True) * 0.01\n",
    "        self.bias = torch.randn(hidden_units, requires_grad=True) * 0.01\n",
    "        self.parameters = self.top_left.parameters() + self.top_right.parameters()\\\n",
    "                        + self.down_left.parameters() + self.down_right.parameters() + [self.weight, self.bias]\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.parameters\n",
    "    \n",
    "    def __call__(self, input_image):\n",
    "        temp = torch.cat((self.top_left(input_image), self.top_right(input_image),\n",
    "                          self.down_left(input_image), self.down_right(input_image)), dim=1)\n",
    "        temp = (temp @ self.weight + self.bias).tanh()\n",
    "        return F.fold(temp.transpose(0, 1).view(1, self.hidden_units, self.row_size * self.col_size),\n",
    "                      (self.row_size, self.col_size),\n",
    "                      (1, self.hidden_units),\n",
    "                      stride=(1, self.hidden_units))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Settings 32 * 32\n",
    "\n",
    "parameters = []\n",
    "\n",
    "# The first layer of mdlstm, transfer to 8 * (8 * 2)\n",
    "first_layer = TwoDimensionalLSTM(16, 2, 8, 8)\n",
    "parameters.extend(first_layer.parameters())\n",
    "\n",
    "# The second layer of mdlstm, transfer to 4 * (8 * 4)\n",
    "second_layer = TwoDimensionalLSTM(4, 4, 4, 8)\n",
    "parameters.extend(second_layer.parameters())\n",
    "\n",
    "# The third layer of mklstm transfer to 2 * (16 * 8)\n",
    "third_layer = TwoDimensionalLSTM(4, 8, 2, 16)\n",
    "parameters.extend(third_layer.parameters())\n",
    "\n",
    "# The fourth layer of mdlstm, transfer to  1 * (64 * 5)\n",
    "fourth_layer = TwoDimensionalLSTM(4, 5, 1, 64)\n",
    "parameters.extend(fourth_layer.parameters())\n",
    "\n",
    "hidden_units1 = 10\n",
    "hidden_units2 = 100\n",
    "output_units = 26\n",
    "\n",
    "# Lookup matrix, reduce the dimension of 320\n",
    "lookup = torch.randn((320, hidden_units1), requires_grad=True) * 0.01\n",
    "bias_lookup = torch.randn(hidden_units1, requires_grad=True) * 0.01\n",
    "\n",
    "# The hidden layer\n",
    "weight1 = torch.randn((hidden_units1, hidden_units2), requires_grad=True) * 0.01\n",
    "bias1 = torch.randn(hidden_units2, requires_grad=True) * 0.01\n",
    "\n",
    "weight2 = torch.randn((hidden_units2, output_units), requires_grad=True) * 0.01\n",
    "bias2 = torch.randn(output_units, requires_grad=True) * 0.01\n",
    "\n",
    "parameters += [lookup, bias_lookup, weight1, bias1, weight2, bias2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_func(minibatch):\n",
    "    # Minibacth is of shape N * 28 * 28\n",
    "    batch_size = minibatch.shape[0]\n",
    "    minibatch = minibatch.view(batch_size, 1, 28, 28)\n",
    "    minibatch = F.unfold(minibatch, kernel_size=4, padding=2, stride=4).transpose(1, 2).view(batch_size, 8, 8, 16)\n",
    "    minibatch = torch.stack([first_layer(batch) for batch in minibatch])\n",
    "    # Minibacth is of shape N * 8 * 16\n",
    "    minibatch = minibatch.view(batch_size, 1, 8, 16)\n",
    "    minibatch = F.unfold(minibatch, kernel_size=2, stride=2).transpose(1, 2).view(batch_size, 4, 8, 4)\n",
    "    minibatch = torch.stack([second_layer(batch) for batch in minibatch])\n",
    "    # Minibatch is of shape N * 4 * 32\n",
    "    minibatch = minibatch.view(batch_size, 1, 4, 32)\n",
    "    minibatch = F.unfold(minibatch, kernel_size=2, stride=2).transpose(1, 2).view(batch_size, 2, 16, 4)\n",
    "    minibatch = torch.stack([third_layer(batch) for batch in minibatch])\n",
    "    # Minibatch is of shape N * 2 * 128\n",
    "    minibatch = minibatch.view(batch_size, 1, 2, 128)\n",
    "    minibatch = F.unfold(minibatch, kernel_size=2, stride=2).transpose(1, 2).view(batch_size, 1, 64, 4)\n",
    "    minibatch = torch.stack([fourth_layer(batch) for batch in minibatch])\n",
    "\n",
    "    minibatch = minibatch.view(batch_size, 320)\n",
    "\n",
    "    minibatch = ((minibatch @ lookup + bias_lookup).tanh() @ weight1 + bias1).tanh() @ weight2 + bias2\n",
    "\n",
    "    return minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Randomly select batch from the dataset\n",
    "selected = torch.randint(high=len(x_train), size=batch_size)\n",
    "batch_x = forward_func(x_train[selected])\n",
    "batch_y = y_train[selected]\n",
    "loss = F.cross_entropy(batch_x, batch_y)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the first layer, scanning from four directions\n",
    "\n",
    "hidden_units1 = 2\n",
    "input_feature1 = 16\n",
    "\n",
    "# Input gate\n",
    "weight_input_gate1_tl = torch.randn((input_feature1, hidden_units1), requires_grad=True)\n",
    "weight_input_state1_tl = torch.randn((hidden_units1, hidden_units1), requires_grad=True)\n",
    "weight_input_cellout1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "bias_input_gate1_tl = torch.randn(hidden_units1, requires_grad=True)\n",
    "\n",
    "# Forget gate\n",
    "weight_forget_gate1_tl = torch.randn((2, input_feature1, hidden_units1), requires_grad=True)\n",
    "weight_forget_cellout1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "weight_forget_state1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "bias_forget_gate1_tl = torch.randn(hidden_units1, requires_grad=True)\n",
    "\n",
    "# Cell\n",
    "weight_cell1_tl = torch.randn((input_feature1, hidden_units1), requires_grad=True)\n",
    "weight_cell_cellout1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "bias_cell1_tl = torch.randn(hidden_units1, requires_grad=True)\n",
    "\n",
    "# Output gate\n",
    "weight_output_gate1_tl = torch.randn((input_feature1, hidden_units1), requires_grad=True)\n",
    "weight_output_cellout1_tl = torch.randn((2, hidden_units1, hidden_units1), requires_grad=True)\n",
    "weight_output_state1_tl = torch.randn((hidden_units1, hidden_units1), requires_grad=True)\n",
    "bias_output_gate1_tl = torch.randn(hidden_units1, requires_grad=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
